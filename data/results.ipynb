{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>PR_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn</td>\n",
       "      <td>test</td>\n",
       "      <td>0.962670</td>\n",
       "      <td>0.875872</td>\n",
       "      <td>0.840696</td>\n",
       "      <td>0.868962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>lstm</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.997466</td>\n",
       "      <td>0.997067</td>\n",
       "      <td>0.997067</td>\n",
       "      <td>0.997701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>test</td>\n",
       "      <td>0.998026</td>\n",
       "      <td>0.995957</td>\n",
       "      <td>0.989290</td>\n",
       "      <td>0.993342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>cnn_gru</td>\n",
       "      <td>train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.998522</td>\n",
       "      <td>0.996835</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>0.995009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Library     Model   Type  Accuracy  Precision    Recall    PR_AUC\n",
       "0   tensorflow       cnn   test  0.962670   0.875872  0.840696  0.868962\n",
       "33     pytorch      lstm  valid  0.997466   0.997067  0.997067  0.997701\n",
       "15  tensorflow  cnn_lstm   test  0.998026   0.995957  0.989290  0.993342\n",
       "8      pytorch   cnn_gru  train  1.000000   1.000000  1.000000  1.000000\n",
       "16  tensorflow  cnn_lstm  valid  0.998522   0.996835  0.992126  0.995009"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(\"results.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>Precision &amp; Recall</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>rnn</td>\n",
       "      <td>train</td>\n",
       "      <td>0.972301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944387</td>\n",
       "      <td>0.986043</td>\n",
       "      <td>0.972194</td>\n",
       "      <td>0.975683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>train</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>0.998092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.999220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>rnn_cnn</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.991130</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>0.979713</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.989604</td>\n",
       "      <td>0.991068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>nn</td>\n",
       "      <td>train</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>0.999486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999743</td>\n",
       "      <td>0.999743</td>\n",
       "      <td>0.999743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn_gru</td>\n",
       "      <td>test</td>\n",
       "      <td>0.995513</td>\n",
       "      <td>0.977513</td>\n",
       "      <td>0.989290</td>\n",
       "      <td>0.984120</td>\n",
       "      <td>0.983402</td>\n",
       "      <td>0.986609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Library     Model   Type  Accuracy  Precision    Recall    PR_AUC  \\\n",
       "46     pytorch       rnn  train  0.972301   1.000000  0.944387  0.986043   \n",
       "17  tensorflow  cnn_lstm  train  0.999744   0.998092  1.000000  0.999046   \n",
       "48     pytorch   rnn_cnn  valid  0.991130   0.999495  0.979713  0.993934   \n",
       "43     pytorch        nn  train  0.999744   0.999486  1.000000  0.999743   \n",
       "9   tensorflow   cnn_gru   test  0.995513   0.977513  0.989290  0.984120   \n",
       "\n",
       "    Precision & Recall     Total  \n",
       "46            0.972194  0.975683  \n",
       "17            0.999046  0.999220  \n",
       "48            0.989604  0.991068  \n",
       "43            0.999743  0.999743  \n",
       "9             0.983402  0.986609  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Precision & Recall\"] = (df[\"Precision\"] + df[\"Recall\"])/2\n",
    "df[\"Total\"] = (df[\"Accuracy\"] + df[\"Precision\"] + df[\"Recall\"] + df[\"PR_AUC\"])/4\n",
    "df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>Precision &amp; Recall</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>rnn_cnn</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.991130</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>0.979713</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.989604</td>\n",
       "      <td>0.991068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>rnn</td>\n",
       "      <td>test</td>\n",
       "      <td>0.974511</td>\n",
       "      <td>0.999014</td>\n",
       "      <td>0.935365</td>\n",
       "      <td>0.979754</td>\n",
       "      <td>0.967189</td>\n",
       "      <td>0.972161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>gru_cnn</td>\n",
       "      <td>train</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.999489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>cnn</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.994720</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.994647</td>\n",
       "      <td>0.995084</td>\n",
       "      <td>0.993922</td>\n",
       "      <td>0.994412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>nn</td>\n",
       "      <td>test</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>0.999315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Library    Model   Type  Accuracy  Precision    Recall    PR_AUC  \\\n",
       "48  pytorch  rnn_cnn  valid  0.991130   0.999495  0.979713  0.993934   \n",
       "44  pytorch      rnn   test  0.974511   0.999014  0.935365  0.979754   \n",
       "29  pytorch  gru_cnn  train  0.999487   0.998980  1.000000  0.999490   \n",
       "4   pytorch      cnn  valid  0.994720   0.993197  0.994647  0.995084   \n",
       "42  pytorch       nn   test  0.999658   0.999315  1.000000  0.999657   \n",
       "\n",
       "    Precision & Recall     Total  \n",
       "48            0.989604  0.991068  \n",
       "44            0.967189  0.972161  \n",
       "29            0.999490  0.999489  \n",
       "4             0.993922  0.994412  \n",
       "42            0.999657  0.999658  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = df[df[\"Library\"]==\"pytorch\"]\n",
    "pt.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train | Valid | Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_train = pt[pt[\"Type\"]==\"train\"]\n",
    "pt_valid = pt[pt[\"Type\"]==\"valid\"]\n",
    "pt_test = pt[pt[\"Type\"]==\"test\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models With The Best Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Library     Model\n",
      "8   pytorch   cnn_gru\n",
      "14  pytorch  cnn_lstm\n",
      "20  pytorch   cnn_rnn\n",
      "37  pytorch  lstm_cnn \n",
      "\n",
      "    Library Model\n",
      "41  pytorch    nn \n",
      "\n",
      "    Library Model\n",
      "42  pytorch    nn\n"
     ]
    }
   ],
   "source": [
    "print(pt_train[pt_train[\"Precision & Recall\"]==pt_train[\"Precision & Recall\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(pt_valid[pt_valid[\"Precision & Recall\"]==pt_valid[\"Precision & Recall\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(pt_test[pt_test[\"Precision & Recall\"]==pt_test[\"Precision & Recall\"].max()][[\"Library\", \"Model\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Library     Model\n",
      "8   pytorch   cnn_gru\n",
      "14  pytorch  cnn_lstm\n",
      "20  pytorch   cnn_rnn\n",
      "37  pytorch  lstm_cnn \n",
      "\n",
      "    Library Model\n",
      "41  pytorch    nn \n",
      "\n",
      "    Library Model\n",
      "42  pytorch    nn\n"
     ]
    }
   ],
   "source": [
    "print(pt_train[pt_train[\"Total\"]==pt_train[\"Total\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(pt_valid[pt_valid[\"Total\"]==pt_valid[\"Total\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(pt_test[pt_test[\"Total\"]==pt_test[\"Total\"].max()][[\"Library\", \"Model\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models With The Best Overall Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>Precision &amp; Recall</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>lstm</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.997769</td>\n",
       "      <td>0.992748</td>\n",
       "      <td>0.990593</td>\n",
       "      <td>0.992301</td>\n",
       "      <td>0.991671</td>\n",
       "      <td>0.993353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>nn</td>\n",
       "      <td>train</td>\n",
       "      <td>0.997179</td>\n",
       "      <td>0.994208</td>\n",
       "      <td>0.984704</td>\n",
       "      <td>0.990482</td>\n",
       "      <td>0.989456</td>\n",
       "      <td>0.991643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn</td>\n",
       "      <td>test</td>\n",
       "      <td>0.962670</td>\n",
       "      <td>0.875872</td>\n",
       "      <td>0.840696</td>\n",
       "      <td>0.868962</td>\n",
       "      <td>0.858284</td>\n",
       "      <td>0.887050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>cnn</td>\n",
       "      <td>train</td>\n",
       "      <td>0.976154</td>\n",
       "      <td>0.919922</td>\n",
       "      <td>0.900574</td>\n",
       "      <td>0.916914</td>\n",
       "      <td>0.910248</td>\n",
       "      <td>0.928391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>lstm</td>\n",
       "      <td>train</td>\n",
       "      <td>0.998311</td>\n",
       "      <td>0.993701</td>\n",
       "      <td>0.993701</td>\n",
       "      <td>0.994123</td>\n",
       "      <td>0.993701</td>\n",
       "      <td>0.994959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Library Model   Type  Accuracy  Precision    Recall    PR_AUC  \\\n",
       "30  tensorflow  lstm  valid  0.997769   0.992748  0.990593  0.992301   \n",
       "40  tensorflow    nn  train  0.997179   0.994208  0.984704  0.990482   \n",
       "0   tensorflow   cnn   test  0.962670   0.875872  0.840696  0.868962   \n",
       "2   tensorflow   cnn  train  0.976154   0.919922  0.900574  0.916914   \n",
       "31  tensorflow  lstm  train  0.998311   0.993701  0.993701  0.994123   \n",
       "\n",
       "    Precision & Recall     Total  \n",
       "30            0.991671  0.993353  \n",
       "40            0.989456  0.991643  \n",
       "0             0.858284  0.887050  \n",
       "2             0.910248  0.928391  \n",
       "31            0.993701  0.994959  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = df[df[\"Library\"]==\"tensorflow\"]\n",
    "tf.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train | Valid | Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train = tf[tf[\"Type\"]==\"train\"]\n",
    "tf_valid = tf[tf[\"Type\"]==\"valid\"]\n",
    "tf_test = tf[tf[\"Type\"]==\"test\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models With The Best Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Library     Model\n",
      "17  tensorflow  cnn_lstm\n",
      "26  tensorflow       gru \n",
      "\n",
      "       Library     Model\n",
      "16  tensorflow  cnn_lstm \n",
      "\n",
      "       Library     Model\n",
      "15  tensorflow  cnn_lstm\n"
     ]
    }
   ],
   "source": [
    "print(tf_train[tf_train[\"Precision & Recall\"]==tf_train[\"Precision & Recall\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(tf_valid[tf_valid[\"Precision & Recall\"]==tf_valid[\"Precision & Recall\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(tf_test[tf_test[\"Precision & Recall\"]==tf_test[\"Precision & Recall\"].max()][[\"Library\", \"Model\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models With The Best Overall Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Library     Model\n",
      "17  tensorflow  cnn_lstm\n",
      "26  tensorflow       gru \n",
      "\n",
      "       Library     Model\n",
      "16  tensorflow  cnn_lstm \n",
      "\n",
      "       Library     Model\n",
      "15  tensorflow  cnn_lstm\n"
     ]
    }
   ],
   "source": [
    "print(tf_train[tf_train[\"Total\"]==tf_train[\"Total\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(tf_valid[tf_valid[\"Total\"]==tf_valid[\"Total\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(tf_test[tf_test[\"Total\"]==tf_test[\"Total\"].max()][[\"Library\", \"Model\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Models - PyTorch + TensorFlow "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train | Valid | Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df[\"Type\"]==\"train\"]\n",
    "df_valid = df[df[\"Type\"]==\"valid\"]\n",
    "df_test = df[df[\"Type\"]==\"test\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models With The Best Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Library     Model\n",
      "8   pytorch   cnn_gru\n",
      "14  pytorch  cnn_lstm\n",
      "20  pytorch   cnn_rnn\n",
      "37  pytorch  lstm_cnn \n",
      "\n",
      "    Library Model\n",
      "41  pytorch    nn \n",
      "\n",
      "    Library Model\n",
      "42  pytorch    nn\n"
     ]
    }
   ],
   "source": [
    "print(df_train[df_train[\"Precision & Recall\"]==df_train[\"Precision & Recall\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(df_valid[df_valid[\"Precision & Recall\"]==df_valid[\"Precision & Recall\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(df_test[df_test[\"Precision & Recall\"]==df_test[\"Precision & Recall\"].max()][[\"Library\", \"Model\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models With The Best Overall Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Library     Model\n",
      "8   pytorch   cnn_gru\n",
      "14  pytorch  cnn_lstm\n",
      "20  pytorch   cnn_rnn\n",
      "37  pytorch  lstm_cnn \n",
      "\n",
      "    Library Model\n",
      "41  pytorch    nn \n",
      "\n",
      "    Library Model\n",
      "42  pytorch    nn\n"
     ]
    }
   ],
   "source": [
    "print(df_train[df_train[\"Total\"]==df_train[\"Total\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(df_valid[df_valid[\"Total\"]==df_valid[\"Total\"].max()][[\"Library\", \"Model\"]], \"\\n\")\n",
    "print(df_test[df_test[\"Total\"]==df_test[\"Total\"].max()][[\"Library\", \"Model\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, PyTorch models are performing better than the TensorFlow models but by how much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision & Recall Difference = 0.9996573582319686 - 0.9926236843149778 = 0.007033673916990724\n",
      "Total Difference = 0.999657526667479 - 0.9941536928844745 = 0.005503833783004453\n"
     ]
    }
   ],
   "source": [
    "ptmax = pt_test[\"Precision & Recall\"].max()\n",
    "tfmax = tf_test[\"Precision & Recall\"].max()\n",
    "print(f\"Precision & Recall Difference = {ptmax} - {tfmax} = {ptmax-tfmax}\")\n",
    "ptmax = pt_test[\"Total\"].max()\n",
    "tfmax = tf_test[\"Total\"].max()\n",
    "print(f\"Total Difference = {ptmax} - {tfmax} = {ptmax-tfmax}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is not far behind, to be fully honest the difference is negligible. Therefore, we need to experiment with both platforms to determine the better library for mobile."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cae526391669789ed67f9d7ca3914bad8ec3b4990d19b0d51fbb51eb5be07e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
